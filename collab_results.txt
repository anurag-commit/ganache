=== Collaborative Voting Evaluation ===
Confusion Matrix:
[[30  0]
 [ 2 28]]

Classification Report:
              precision    recall  f1-score   support

           0       0.94      1.00      0.97        30
           1       1.00      0.93      0.97        30

    accuracy                           0.97        60
   macro avg       0.97      0.97      0.97        60
weighted avg       0.97      0.97      0.97        60

Accuracy: 0.9667
